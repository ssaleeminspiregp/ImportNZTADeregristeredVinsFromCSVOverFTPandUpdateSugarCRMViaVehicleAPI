substitutions:
  # Region where Cloud Run, Scheduler, and Artifact Registry operate.
  _REGION: australia-southeast1
  # Artifact Registry repository used for versioned images.
  _REPO: all-brands-nzta-deregistered-vins
  # Base image name shared by both Cloud Run services.
  _IMAGE_NAME: all-brands-nzta-deregistered-vins
  # Cloud Run service names.
  _INGEST_SERVICE: all-brands-nzta-deregistered-vins-ingest
  _SYNC_SERVICE: all-brands-nzta-deregistered-vins-sync
  # Pub/Sub resources.
  _INGEST_TOPIC: all-brands-nzta-deregistered-vins-ingest-trigger
  _SYNC_TOPIC: all-brands-nzta-deregistered-vins-sync-trigger
  _INGEST_SUB: all-brands-nzta-deregistered-vins-ingest-runner
  _SYNC_SUB: all-brands-nzta-deregistered-vins-sync-runner
  _DLQ_TOPIC: all-brands-nzta-deregistered-vins-dlq
  # Scheduler jobs + cron specs (NZT).
  _INGEST_JOB: all-brands-nzta-deregistered-vins-ingest-daily
  _SYNC_JOB: all-brands-nzta-deregistered-vins-sync-daily
  _INGEST_SCHEDULE: "0 4 * * *"
  _SYNC_SCHEDULE: "0 6 * * *"

logsBucket: gs://ib4t-integration-adh-data-utopia-cloudbuild-logs

options:
  logging: GCS_ONLY

steps:
  # 0) Enable required APIs (idempotent if already enabled).
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk
    entrypoint: bash
    args:
      - -c
      - |
        set -euo pipefail
        gcloud services enable appengine.googleapis.com cloudscheduler.googleapis.com

  # 1) Ensure Artifact Registry repository exists.
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk
    entrypoint: bash
    args:
      - -c
      - |
        set -euo pipefail
        if ! gcloud artifacts repositories describe "$_REPO" --location="$_REGION" >/dev/null 2>&1; then
          gcloud artifacts repositories create "$_REPO" \
            --repository-format=docker \
            --location="$_REGION" \
            --description="Container images for the NZTA deregistered VIN pipelines"
        fi

  # 2) Guarantee the GCS landing bucket exists (no delete to retain audit files).
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk
    entrypoint: bash
    args:
      - -c
      - |
        set -euo pipefail
        BUCKET="${_GCS_BUCKET:-all-brands-nzta-deregistered-vins-temp-do-not-delete}"
        if ! gsutil ls -b "gs://$${BUCKET}" >/dev/null 2>&1; then
          gsutil mb -l "$_REGION" "gs://$${BUCKET}"
        fi

  # 3) Guarantee the Pub/Sub topics exist.
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk
    entrypoint: bash
    args:
      - -c
      - |
        set -euo pipefail
        for topic in "$_INGEST_TOPIC" "$_SYNC_TOPIC"; do
          gcloud pubsub topics describe "$topic" >/dev/null 2>&1 || \
          gcloud pubsub topics create "$topic"
        done

  # 4) Guarantee the DLQ topic exists and Pub/Sub SA can publish to it.
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk
    entrypoint: bash
    args:
      - -c
      - |
        set -euo pipefail
        gcloud pubsub topics describe "$_DLQ_TOPIC" >/dev/null 2>&1 || \
        gcloud pubsub topics create "$_DLQ_TOPIC"
        PROJECT_NUMBER="$(gcloud projects describe "$(gcloud config get-value project)" --format='value(projectNumber)')"
        gcloud pubsub topics add-iam-policy-binding "$_DLQ_TOPIC" \
          --member="serviceAccount:service-$${PROJECT_NUMBER}@gcp-sa-pubsub.iam.gserviceaccount.com" \
          --role="roles/pubsub.publisher" \
          --quiet

  # 4) Build the Cloud Run container image from the current workspace.
  - name: gcr.io/cloud-builders/docker
    args:
      [
        "build",
        "-t",
        "$_REGION-docker.pkg.dev/adh-data-utopia/$_REPO/$_IMAGE_NAME:$SHORT_SHA",
        ".",
      ]

  # 5) Push the image to Artifact Registry so Cloud Run can pull it.
  - name: gcr.io/cloud-builders/docker
    args:
      [
        "push",
        "$_REGION-docker.pkg.dev/adh-data-utopia/$_REPO/$_IMAGE_NAME:$SHORT_SHA",
      ]

  # 6) Deploy (or update) the ingest Cloud Run service.
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk
    entrypoint: gcloud
    args:
      [
        "run","deploy","$_INGEST_SERVICE",
        "--image","$_REGION-docker.pkg.dev/adh-data-utopia/$_REPO/$_IMAGE_NAME:$SHORT_SHA",
        "--region","$_REGION",
        "--platform","managed",
        "--allow-unauthenticated",
        "--timeout","900",
        "--cpu","2",
        "--memory","1Gi",
        "--max-instances","1",
        "--min-instances","1",
        "--service-account","ib4t-integration@adh-data-utopia.iam.gserviceaccount.com",
        "--set-env-vars",
        "FTP_CONFIG_SECRET=${_FTP_CONFIG_SECRET},SUGAR_CONFIG_SECRET=${_SUGAR_CONFIG_SECRET},FTP_REMOTE_PATH=${_FTP_REMOTE_PATH},FTP_FILE_PATTERN=${_FTP_FILE_PATTERN},GCS_BUCKET=${_GCS_BUCKET},GCS_RAW_PREFIX=${_GCS_RAW_PREFIX},GCS_PROCESSED_PREFIX=${_GCS_PROCESSED_PREFIX},GCS_ERROR_PREFIX=${_GCS_ERROR_PREFIX},ALLOWED_MAKES=${_ALLOWED_MAKES},BQ_STAGE_DATASET=${_BQ_STAGE_DATASET},BQ_STAGE_TABLE=${_BQ_STAGE_TABLE},BQ_STAGE_LOCATION=${_BQ_STAGE_LOCATION},EMAIL_SENDER=${_EMAIL_SENDER},EMAIL_RECIPIENTS=${_EMAIL_RECIPIENTS},SUCCESS_EMAIL_RECIPIENTS=${_SUCCESS_EMAIL_RECIPIENTS},ERROR_EMAIL_RECIPIENTS=${_ERROR_EMAIL_RECIPIENTS},SMTP_HOST=${_SMTP_HOST},SMTP_PORT=${_SMTP_PORT},SMTP_USERNAME=${_SMTP_USERNAME},SMTP_PASSWORD=${_SMTP_PASSWORD},SMTP_USE_TLS=${_SMTP_USE_TLS},SMTP_TIMEOUT=${_SMTP_TIMEOUT},SMTP_DEBUG=${_SMTP_DEBUG},EMAIL_SERVER_CONFIG_SECRET=${_EMAIL_SERVER_CONFIG_SECRET},LOG_LEVEL=${_LOG_LEVEL},SERVICE_MODE=ingest"
      ]

  # 7) Deploy (or update) the sync Cloud Run service.
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk
    entrypoint: gcloud
    args:
      [
        "run","deploy","$_SYNC_SERVICE",
        "--image","$_REGION-docker.pkg.dev/adh-data-utopia/$_REPO/$_IMAGE_NAME:$SHORT_SHA",
        "--region","$_REGION",
        "--platform","managed",
        "--allow-unauthenticated",
        "--timeout","900",
        "--cpu","2",
        "--memory","1Gi",
        "--max-instances","1",
        "--min-instances","1",
        "--service-account","ib4t-integration@adh-data-utopia.iam.gserviceaccount.com",
        "--set-env-vars",
        "FTP_CONFIG_SECRET=${_FTP_CONFIG_SECRET},SUGAR_CONFIG_SECRET=${_SUGAR_CONFIG_SECRET},FTP_REMOTE_PATH=${_FTP_REMOTE_PATH},FTP_FILE_PATTERN=${_FTP_FILE_PATTERN},GCS_BUCKET=${_GCS_BUCKET},GCS_RAW_PREFIX=${_GCS_RAW_PREFIX},GCS_PROCESSED_PREFIX=${_GCS_PROCESSED_PREFIX},GCS_ERROR_PREFIX=${_GCS_ERROR_PREFIX},ALLOWED_MAKES=${_ALLOWED_MAKES},BQ_STAGE_DATASET=${_BQ_STAGE_DATASET},BQ_STAGE_TABLE=${_BQ_STAGE_TABLE},BQ_STAGE_LOCATION=${_BQ_STAGE_LOCATION},EMAIL_SENDER=${_EMAIL_SENDER},EMAIL_RECIPIENTS=${_EMAIL_RECIPIENTS},SUCCESS_EMAIL_RECIPIENTS=${_SUCCESS_EMAIL_RECIPIENTS},ERROR_EMAIL_RECIPIENTS=${_ERROR_EMAIL_RECIPIENTS},SMTP_HOST=${_SMTP_HOST},SMTP_PORT=${_SMTP_PORT},SMTP_USERNAME=${_SMTP_USERNAME},SMTP_PASSWORD=${_SMTP_PASSWORD},SMTP_USE_TLS=${_SMTP_USE_TLS},SMTP_TIMEOUT=${_SMTP_TIMEOUT},SMTP_DEBUG=${_SMTP_DEBUG},EMAIL_SERVER_CONFIG_SECRET=${_EMAIL_SERVER_CONFIG_SECRET},LOG_LEVEL=${_LOG_LEVEL},SERVICE_MODE=sync"
      ]

  # 8) Grant the Pub/Sub push identity invoke rights on both services.
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk
    entrypoint: bash
    args:
      - -c
      - |
        set -euo pipefail
        for svc in "$_INGEST_SERVICE" "$_SYNC_SERVICE"; do
          gcloud run services add-iam-policy-binding "$svc" \
            --region="$_REGION" \
            --member="serviceAccount:ib4t-integration@adh-data-utopia.iam.gserviceaccount.com" \
            --role="roles/run.invoker"
        done

  # 9) Recreate the push subscription pointing to the ingest service URL.
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk
    entrypoint: bash
    args:
      - -c
      - |
        set -euo pipefail
        SERVICE_URL="$(gcloud run services describe $_INGEST_SERVICE --region $_REGION --format='value(status.url)')"
        if gcloud pubsub subscriptions describe "$_INGEST_SUB" >/dev/null 2>&1; then
          gcloud pubsub subscriptions delete "$_INGEST_SUB" --quiet
        fi
        gcloud pubsub subscriptions create "$_INGEST_SUB" \
          --topic="$_INGEST_TOPIC" \
          --push-endpoint="$${SERVICE_URL}/" \
          --push-auth-service-account="ib4t-integration@adh-data-utopia.iam.gserviceaccount.com" \
          --dead-letter-topic="$_DLQ_TOPIC" \
          --max-delivery-attempts="5" \
          --min-retry-delay="0s" \
          --max-retry-delay="0s"

  # 10) Recreate the push subscription pointing to the sync service URL.
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk
    entrypoint: bash
    args:
      - -c
      - |
        set -euo pipefail
        SERVICE_URL="$(gcloud run services describe $_SYNC_SERVICE --region $_REGION --format='value(status.url)')"
        if gcloud pubsub subscriptions describe "$_SYNC_SUB" >/dev/null 2>&1; then
          gcloud pubsub subscriptions delete "$_SYNC_SUB" --quiet
        fi
        gcloud pubsub subscriptions create "$_SYNC_SUB" \
          --topic="$_SYNC_TOPIC" \
          --push-endpoint="$${SERVICE_URL}/" \
          --push-auth-service-account="ib4t-integration@adh-data-utopia.iam.gserviceaccount.com" \
          --dead-letter-topic="$_DLQ_TOPIC" \
          --max-delivery-attempts="5" \
          --min-retry-delay="0s" \
          --max-retry-delay="0s"

  # 11) Create or update the Scheduler jobs that publish daily triggers.
  - name: gcr.io/google.com/cloudsdktool/cloud-sdk
    entrypoint: bash
    args:
      - -c
      - |
        set -euo pipefail
        TZ="Pacific/Auckland"
        if gcloud scheduler jobs describe "$_INGEST_JOB" --location="$_REGION" >/dev/null 2>&1; then
          gcloud scheduler jobs update pubsub "$_INGEST_JOB" \
            --location="$_REGION" \
            --schedule="$_INGEST_SCHEDULE" \
            --time-zone="$${TZ}" \
            --topic="$_INGEST_TOPIC" \
            --message-body="{}"
        else
          gcloud scheduler jobs create pubsub "$_INGEST_JOB" \
            --location="$_REGION" \
            --schedule="$_INGEST_SCHEDULE" \
            --time-zone="$${TZ}" \
            --topic="$_INGEST_TOPIC" \
            --message-body="{}"
        fi
        if gcloud scheduler jobs describe "$_SYNC_JOB" --location="$_REGION" >/dev/null 2>&1; then
          gcloud scheduler jobs update pubsub "$_SYNC_JOB" \
            --location="$_REGION" \
            --schedule="$_SYNC_SCHEDULE" \
            --time-zone="$${TZ}" \
            --topic="$_SYNC_TOPIC" \
            --message-body="{}"
        else
          gcloud scheduler jobs create pubsub "$_SYNC_JOB" \
            --location="$_REGION" \
            --schedule="$_SYNC_SCHEDULE" \
            --time-zone="$${TZ}" \
            --topic="$_SYNC_TOPIC" \
            --message-body="{}"
        fi

images:
  # Artifact reference recorded for reproducibility/auditing.
  - "$_REGION-docker.pkg.dev/adh-data-utopia/$_REPO/$_IMAGE_NAME:$SHORT_SHA"
